<div align="center">
  <a href="http://zhijian.readthedocs.io"><img width="450px" height="auto" src="https://github.com/zhangyikaii/LAMDA-ZhiJian/raw/main/assests/logo.png?raw=true"></a>
</div>

&nbsp;

<div align="center">
    <img src="https://img.shields.io/badge/License-MIT-<COLOR>.svg?style=for-the-badge" alt="Generic badge", height="21">
    <img src="https://img.shields.io/github/actions/workflow/status/zhangyikaii/LAMDA-ZhiJian/tests.yml?branch=main&style=for-the-badge" alt="GitHub Workflow Status (branch)", height="21">
    <img src="https://img.shields.io/readthedocs/smp?style=for-the-badge&logo=readthedocs&logoColor=white" alt="Read the Docs", height="21">
    <br>
    <img src="https://img.shields.io/pypi/v/ZhiJian?color=blue&style=for-the-badge&logo=pypi&logoColor=white" alt="PyPI", height="21">
    <img src="https://img.shields.io/pypi/dm/ZhiJian?style=for-the-badge&color=blue" alt="PyPI - Downloads", height="21">
    <br>
    <img src="https://img.shields.io/badge/PYTORCH-1.4+-red?style=for-the-badge&logo=pytorch" alt="PyTorch - Version", height="21">
    <img src="https://img.shields.io/badge/PYTHON-3.7+-red?style=for-the-badge&logo=python&logoColor=white" alt="Python - Version", height="21">
</div>
<h4 align="center">
    <p>
        æ‰§ç®€ï¼šä¸ºé¢„è®­ç»ƒæ¨¡å‹å¤ç”¨æä¾›å¿«é€Ÿéƒ¨ç½²çš„ç»Ÿä¸€æ–¹æ¡ˆ
    <p>
    <p>
        <a href="https://arxiv.org/abs/2308.09158">[è®ºæ–‡]</a> [<b>ä»£ç </b>] <a href="https://zhijian.readthedocs.io/en/latest/#">[æ–‡æ¡£]</a>
    <p>
    <p>
        <a href="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/README.md">English</a> |
        <b>ä¸­æ–‡</b>
    <p>
</h4>


**ZhiJian** ([**æ‰§ç®€**é©­ç¹](https://baike.baidu.com/item/%E6%89%A7%E7%AE%80%E9%A9%AD%E7%B9%81)) æ˜¯ä¸€ä¸ªåŸºäº`PyTorch`æ¡†æ¶çš„*æ¨¡å‹å¤ç”¨*å·¥å…·åŒ…ï¼Œä¸ºå†æ¬¡åˆ©ç”¨è®¸å¤š**åŸºåº§é¢„è®­ç»ƒæ¨¡å‹**ä»¥åŠå·²æœ‰ä»»åŠ¡ä¸Šçš„**å·²è®­ç»ƒæ¨¡å‹**ï¼Œå……åˆ†æå–å®ƒä»¬è•´å«çš„çŸ¥è¯†**å¹¶æ¿€å‘ç›®æ ‡ä»»åŠ¡ä¸Šçš„å­¦ä¹ **ï¼Œæä¾›äº†å…¨é¢ä¸”ç»Ÿä¸€çš„å¤ç”¨æ–¹æ¡ˆã€‚

è¿‘å¹´æ¥äººå·¥æ™ºèƒ½çš„è“¬å‹ƒå‘å±•äº§å‡ºäº†è®¸å¤šå¼€æºé¢„è®­ç»ƒæ¨¡å‹ï¼ˆPre-Trained Modelsï¼‰ï¼Œä¾‹å¦‚PyTorchã€TensorFlowå’ŒHuggingFace Transformersç­‰å¹³å°ä¸Šå­˜å‚¨äº†å¤§é‡æ¨¡å‹èµ„æºã€‚æ¨¡å‹å¤ç”¨é€šè¿‡**é€‚é…ç½‘ç»œç»“æ„ã€å®šåˆ¶å­¦ä¹ æ–¹å¼ä»¥åŠä¼˜åŒ–æ¨ç†ç­–ç•¥**æ¥åˆ©ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¥**è¿›ä¸€æ­¥åŠ é€Ÿå’Œå¼ºåŒ–**ç›®æ ‡ä»»åŠ¡ä¸Šçš„å­¦ä¹ ï¼Œè¿™å°†ä¸ºæœºå™¨å­¦ä¹ ç¤¾åŒºæºæºä¸æ–­åœ°è´¡çŒ®ä»·å€¼ã€‚

![overview](https://github.com/zhangyikaii/LAMDA-ZhiJian/raw/main/assests/overview.png?raw=true)

ä¸ºäº†å…¨é¢è€Œç®€æ´åœ°è€ƒè™‘å„ç§æ¨¡å‹å¤ç”¨ç­–ç•¥ï¼Œ**ZhiJian** å°†å¤ç”¨æ–¹æ³•å½’ç±»ä¸ºä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š**æ„å»ºè€…**ï¼Œ**å¾®è°ƒè€…**ï¼Œå’Œ**èåˆè€…**ï¼Œå®ƒä»¬åˆ†åˆ«ä¸ç›®æ ‡ä»»åŠ¡éƒ¨ç½²æ—¶æ¨¡å‹å‡†å¤‡é˜¶æ®µã€å­¦ä¹ é˜¶æ®µå’Œæ¨ç†é˜¶æ®µç›¸å¯¹åº”ã€‚æ‰§ç®€å·¥å…·åŒ…æä¾›çš„æ¥å£å’Œæ–¹æ³•åŒ…æ‹¬ï¼š

<details>
<summary style="margin-left: 2px;"><b>æ„å»ºè€…</b> æ¨¡å— [<em>ç‚¹å‡»ä»¥å±•å¼€</em>]<p style="margin-left: 12px;">æ„å»ºè€…æ¨¡å—åŒ…å«<b>ä¿®æ”¹é¢„è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”ç›®æ ‡ä»»åŠ¡</b>ï¼Œå¼•å…¥å…·æœ‰ä»»åŠ¡ç‰¹å®šç»“æ„çš„å…¨æ–°å¯å­¦ä¹ å‚æ•°ï¼ŒåŒæ—¶ç¡®å®šé‡ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„æŸäº›éƒ¨åˆ†ã€‚</p></summary>
  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Linear Probing</strong> & <strong>Partial-k</strong>, <em>How transferable are features in deep neural networks?</em> In: NeurIPS'14. <a href="https://arxiv.org/pdf/1411.1792.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/linear_probing.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Adapter</strong>, <em>Parameter-Efficient Transfer Learning for NLP.</em> In: ICML'19. <a href="https://arxiv.org/pdf/1902.00751.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/adapter.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Diff Pruning</strong>, <em>Parameter-Efficient Transfer Learning with Diff Pruning.</em> In: ACL'21. <a href="https://arxiv.org/pdf/2012.07463.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/diff_pruning.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;LoRA</strong>, <em>LoRA: Low-Rank Adaptation of Large Language Models.</em> In: ICLR'22. <a href="https://arxiv.org/pdf/2106.09685.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/lora.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Visual Prompt Tuning / Prefix</strong>, <em>Visual Prompt Tuning.</em> In: ECCV'22. <a href="https://arxiv.org/pdf/2203.12119.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/visual_prompt_tuning.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Scaling &amp; Shifting</strong>, <em>Scaling &amp; Shifting Your Features: A New Baseline for Efficient Model Tuning.</em> In: NeurIPS'22. <a href="https://arxiv.org/pdf/2210.08823.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/scaling_and_shifting.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;AdaptFormer</strong>, <em>AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition.</em> In: NeurIPS'22. <a href="https://arxiv.org/pdf/2205.13535.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/adapterformer.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;BitFit</strong>, <em>BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models.</em> In: ACL'22. <a href="https://arxiv.org/pdf/2106.10199.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/bitfit.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Convpass</strong>, <em>Convolutional Bypasses Are Better Vision Transformer Adapters.</em> In: Tech Report 07-2022. <a href="https://arxiv.org/pdf/2207.07039.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/convpass.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Fact-Tuning</strong>, <em>FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer.</em> In: AAAI'23. <a href="https://arxiv.org/pdf/2212.03145.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/fact_tuning.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>
</details>

<details>
<summary style="margin-left: 2px;"><b>å¾®è°ƒè€…</b> æ¨¡å— [<em>ç‚¹å‡»ä»¥å±•å¼€</em>]<p style="margin-left: 12px;">å¾®è°ƒè€…æ¨¡å—ä¸“æ³¨äº<b>åœ¨é¢„è®­ç»ƒæ¨¡å‹çŸ¥è¯†çš„å¼•å¯¼ä¸‹è®­ç»ƒç›®æ ‡æ¨¡å‹</b>ï¼Œä»¥åŠ å¿«ä¼˜åŒ–è¿‡ç¨‹ï¼Œä¾‹å¦‚é€šè¿‡è°ƒæ•´è®­ç»ƒç›®æ ‡ã€ä¼˜åŒ–å™¨æˆ–æ­£åˆ™åŒ–å™¨ç­‰æ–¹å¼ã€‚</p></summary>
  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Knowledge Transfer</strong>, <em>NeC4.5: neural ensemble based C4.5.</em> In: IEEE Trans. Knowl. Data Eng. 2004. <a href="https://ieeexplore.ieee.org/document/1294896">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/knowledge_transfer.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;FitNet</strong>, <em>FitNets: Hints for Thin Deep Nets.</em> In: ICLR'15. <a href="https://arxiv.org/pdf/1412.6550.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/fitnet.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;LwF</strong>, <em>Learning without Forgetting.</em> In: CVPR'19. <a href="https://arxiv.org/pdf/1606.09282.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/learning_without_forgetting.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;FSP</strong>, <em>A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning.</em> In: CVPR'17. <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/fsp.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;NST</strong>, <em>Like What You Like: Knowledge Distill via Neuron Selectivity Transfer.</em> In: CVPR'17. <a href="https://arxiv.org/pdf/1707.01219.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/nst.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;RKD</strong>, <em>Relational Knowledge Distillation.</em> In: CVPR'19. <a href="https://arxiv.org/pdf/1904.05068.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/rkd.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;SPKD</strong>, <em>Similarity-Preserving Knowledge Distillation.</em> In: CVPR'19. <a href="https://arxiv.org/pdf/1907.09682.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/spkd.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;CRD</strong>, <em>Contrastive Representation Distillation.</em> In: ICLR'20. <a href="https://arxiv.org/pdf/1910.10699.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/crd.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;REFILLED</strong>, <em>Distilling Cross-Task Knowledge via Relationship Matching.</em> In: CVPR'20. <a href="http://www.lamda.nju.edu.cn/lus/files/CVPR20_ReFilled.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/refilled.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;WiSE-FT</strong>, <em>Robust fine-tuning of zero-shot models.</em> In: CVPR'22. <a href="https://arxiv.org/pdf/2109.01903.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/wise_tune.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;L<sup>2</sup> penalty / L<sup>2</sup>-SP</strong>, <em>Explicit Inductive Bias for Transfer Learning with Convolutional Networks.</em> In: ICML'18. <a href="https://arxiv.org/pdf/1802.01483.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/l_2_penalty.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Spectral Norm</strong>, <em>Spectral Normalization for Generative Adversarial Networks.</em> In: ICLR'18. <a href="https://arxiv.org/pdf/1802.05957.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/spectral_norm.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;BSS</strong>, <em>Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning.</em> In: NeurIPS'19. <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/c6bff625bdb0393992c9d4db0c6bbe45-Paper.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/bss.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;DELTA</strong>, <em>DELTA: DEep Learning Transfer using Feature Map with Attention for Convolutional Networks.</em> In: ICLR'19. <a href="https://arxiv.org/pdf/1901.09229.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/delta.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;DeiT</strong>, <em>Training data-efficient image transformers & distillation through attention.</em> In: ICML'21. <a href="https://arxiv.org/pdf/2012.12877.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/deit.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;DIST</strong>, <em>Knowledge Distillation from A Stronger Teacher.</em> In: NeurIPS'22. <a href="https://arxiv.org/pdf/2205.10536.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/dist.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>
</details>

<details>
<summary style="margin-left: 2px;"><b>èåˆè€…</b> æ¨¡å— [<em>ç‚¹å‡»ä»¥å±•å¼€</em>]<p style="margin-left: 12px;">èåˆè€…æ¨¡å—<b>åœ¨æ¨ç†é˜¶æ®µ</b>é€šè¿‡å¤ç”¨é¢„è®­ç»ƒç‰¹å¾ï¼Œæˆ–èåˆæ¥è‡ªé€‚é…åçš„é¢„è®­ç»ƒè¾“å‡ºæ¥è·å¾—æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚</p></summary>
  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Nearest Class Mean</strong>, <em>Generalizing to new classes at near-zero cost.</em> In: TPAMI'13. <a href="https://ieeexplore.ieee.org/document/6517188">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/ncm.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;SimpleShot</strong>, <em>SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning.</em> In: CVPR'19. <a href="https://arxiv.org/pdf/1911.04623.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/simpleshot.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Head2Toe</strong>, <em>Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning.</em> In: ICML'22. <a href="https://arxiv.org/pdf/2201.03529.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/head2toe.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>
  
  <details>
    <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;VQT</strong>, <em>Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning.</em> In: CVPR'23. <a href="https://arxiv.org/pdf/2212.03220.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
    <div style="text-align: center;">
      <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/vqt.png?raw=true" alt="WSFG" width="auto" height="300px" />
    </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;via Optimal Transport</strong>, <em>Model Fusion via Optimal Transport.</em> In: NeurIPS'20. <a href="https://arxiv.org/pdf/1910.05653.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/otfusion.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Model Soup</strong> <em>Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.</em> In: ICML'22. <a href="https://arxiv.org/pdf/2203.05482.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/modelsoup.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Fisher Merging</strong> <em>Merging Models with Fisher-Weighted Averaging.</em> In: NeurIPS'22. <a href="https://arxiv.org/pdf/2111.09832.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/fishermerging.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Deep Model Reassembly</strong> <em>Deep Model Reassembly.</em> In: NeurIPS'22. <a href="https://arxiv.org/pdf/2210.17409.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/dmr.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;REPAIR</strong> <em>REPAIR: REnormalizing Permuted Activations for Interpolation Repair.</em> In: ICLR'23. <a href="https://arxiv.org/pdf/2211.08403.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/repair.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;Git Re-Basin</strong> <em>Git Re-Basin: Merging Models modulo Permutation Symmetries.</em> In: ICLR'23. <a href="https://arxiv.org/pdf/2209.04836.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/gitrebasin.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>

  <details>
  <summary style="margin-left: 12px;"><strong>&nbsp;&nbsp;&nbsp;&nbsp;ZipIt</strong> <em>ZipIt! Merging Models from Different Tasks without Training.</em> In: ICLR'23. <a href="https://arxiv.org/pdf/2305.03053.pdf">[Paper]</a> <a href="https://github.com">[Code]</a></summary>
  <div style="text-align: center;">
    <img src="https://github.com/zhangyikaii/LAMDA-ZhiJian/blob/main/assests/zipit.png?raw=true" alt="WSFG" width="auto" height="300px" />
  </div>
  </details>
</details>

<!-- &nbsp; -->

ğŸ’¡ **ZhiJian** è¿˜åŒ…å«å¦‚ä¸‹ç‰¹è‰²:

+ æ”¯æŒå¤ç”¨è®¸å¤šå¼€æºé¢„è®­ç»ƒæ¨¡å‹åº“, åŒ…å«ï¼š
  +  PyTorch [Torchvision](https://pytorch.org/vision/stable/models.html); OpenAI [CLIP](https://github.com/openai/CLIP); ğŸ¤—Hugging Face [PyTorch Image Models (timm)](https://github.com/huggingface/pytorch-image-models), [Transformers](https://github.com/huggingface/transformers)
  + å…¶ä»–æµè¡Œçš„å¤ç”¨æ¡†æ¶ï¼Œ*ä¾‹å¦‚*ï¼Œ[vit-pytorch](https://github.com/lucidrains/vit-pytorch) (stars [14k](https://github.com/lucidrains/vit-pytorch/stargazers)).
  + å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…å« [baichuan](https://huggingface.co/baichuan-inc/baichuan-7B), [LLaMA](https://github.com/facebookresearch/llama), and [BLOOM](https://huggingface.co/bigscience/bloom).
+ æç®€ä¸Šæ‰‹ä¸ä¸ªæ€§åŒ–å®šåˆ¶ï¼š
  + åœ¨10åˆ†é’Ÿå†…æé€Ÿå¼€å§‹ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Ho1R6h5FEg6zXBJVauXcBnSpBrfi6JmN?usp=sharing)
  + ä¸€æ­¥æ­¥åœ°å®šåˆ¶æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1PKy1U7DyAy5AJYIBv5VEoHWEDJ6NCwTZ?usp=sharing)
  + éšå¿ƒæ‰€æ¬²åœ°åˆ›é€ æ¨¡å‹å¤ç”¨çš„æ–°æ–¹æ³• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vHQjlaAGhoeiTVAwOrSQCraAlDvWOlh9?usp=sharing)
+ ç®€æ´çš„ç»“æ„åšå¾—å¤§äº‹å„¿
  + åŸºç¡€ä»£ç ä»…çº¦5kè¡Œï¼Œå¼•å…¥æ–¹æ³•å°±åƒæ­ç§¯æœ¨ä¸€æ ·
  + åœ¨ VTAB-M åŸºçº¿æ ‡å‡†ä¸Šçš„æœ€ä¼˜æ€§èƒ½ï¼Œè¶…è¿‡ **10k** æ¬¡å®éªŒ [[here]](https://github.com/zhangyikaii/LAMDA-ZhiJian/tree/main/results)
  + æ”¯æŒç”¨æˆ·å‹å¥½çš„æŒ‡å¼•å’Œå…¨é¢çš„æ–‡æ¡£æ¥å®šåˆ¶åŒ–æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹ [[here]](https://zhijian.readthedocs.io/en/latest/tutorials/get_started.html)

> â€œæ‰§ç®€é©­ç¹â€çš„æ„æ€æ˜¯ç”¨ç®€æ´é«˜æ•ˆçš„æ–¹æ³•é©¾é©­çº·ç¹å¤æ‚çš„äº‹ç‰©ã€‚â€œç¹â€è¡¨ç¤ºç°æœ‰é¢„è®­ç»ƒæ¨¡å‹å’Œå¤ç”¨æ–¹æ³•ç§ç±»å¤šã€å·®å¼‚å¤§ã€éƒ¨ç½²éš¾ï¼Œæ‰€ä»¥å–å"æ‰§ç®€"çš„æ„æ€æ˜¯é€šè¿‡è¯¥å·¥å…·åŒ…ï¼Œèƒ½è½»æ¾åœ°é©¾é©­æ¨¡å‹å¤ç”¨æ–¹æ³•ï¼Œæ˜“ä¸Šæ‰‹ã€å¿«å¤ç”¨ã€ç¨³ç²¾åº¦ï¼Œæœ€å¤§é™åº¦åœ°å”¤é†’é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†ã€‚

&nbsp;

## ğŸ•¹ï¸ å¿«é€Ÿå¼€å§‹

1. ç”¨ [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html "conda-env"), [venv](https://docs.python.org/3/library/venv.html), æˆ– [virtualenv](https://virtualenv.pypa.io/en/latest/) éƒ¨ç½² Python 3.7+ çš„ç¯å¢ƒ

2. ä½¿ç”¨ pip æ¥å®‰è£… ZhiJianï¼š
   ```bash
   $ pip install zhijian
   ```

   + [Option] Install with the newest version through GitHub:
      ```bash
      $ pip install git+https://github.com/ZhangYikaii/LAMDA-ZhiJian.git@main --upgrade
      ```

3. æ‰“å¼€ Python æ§åˆ¶å°ï¼Œè¾“å…¥
   ```python
   import zhijian
   print(zhijian.__version__)
   ```
   å¦‚æœæ²¡æœ‰é”™è¯¯å‡ºç°ï¼Œåˆ™æˆåŠŸå®‰è£…äº†æ‰§ç®€å·¥å…·åŒ…


&nbsp;

## æ–‡æ¡£

ğŸ“š ç›¸å…³æ•™ç¨‹å’ŒAPIæ–‡æ¡£è¯·ç‚¹å‡» [ZhiJian.readthedocs.io](https://zhijian.readthedocs.io/)

&nbsp;

## ä¸ºä»€ä¹ˆä½¿ç”¨æ‰§ç®€å·¥å…·åŒ…ï¼Ÿ

![architecture](https://github.com/zhangyikaii/LAMDA-ZhiJian/raw/main/assests/architecture.png?raw=true)

<table>
  <tr>
    <td colspan="9" style="border-bottom: 2px solid black;"></td>
  </tr>
  <tr>
    <td><b>Related Library</b></td>
    <td><b>GitHub Stars</b></td>
    <td><b># of Alg.<sup>(1)</sup></b></td>
    <td><b># of Model<sup>(1)</sup></b></td>
    <td><b># of Dataset<sup>(1)</sup></b></td>
    <td><b># of Fields<sup>(2)</sup></b></td>
    <td><b>LLM Supp.</b></td>
    <td><b>Docs.</b></td>
    <td><b>Last Update</b></td>
  </tr>
  <tr>
    <td><a href="https://github.com/huggingface/peft">PEFT</a></td>
    <td><a href="https://github.com/huggingface/peft/stargazers">
      <img src="https://img.shields.io/github/stars/huggingface/peft" alt="GitHub stars">
    </a></td>
    <td>6</td>
    <td>~15</td>
    <td>â–<sup>(3)</sup></td>
    <td>1<sup>(a)</sup></td>
    <td>âœ”ï¸</td>
    <td>âœ”ï¸</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/huggingface/peft?label=last%20update">
    </a>
    </td>
  </tr>
  <tr>
    <td><a href="https://github.com/adapter-hub/adapter-transformers">adapter-transformers</a></td>
    <td><a href="https://github.com/adapter-hub/adapter-transformers/stargazers">
      <img src="https://img.shields.io/github/stars/adapter-hub/adapter-transformers" alt="GitHub stars">
    </a></td>
    <td>10</td>
    <td>~15</td>
    <td>â–<sup>(3)</sup></td>
    <td>1<sup>(a)</sup></td>
    <td>âŒ</td>
    <td>âœ”ï¸</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/adapter-hub/adapter-transformers?label=last%20update">
    </a>
    </td>
  </tr>
  <tr>
    <td><a href="https://github.com/hiyouga/LLaMA-Efficient-Tuning">LLaMA-Efficient-Tuning</a></td>
    <td><a href="https://github.com/hiyouga/LLaMA-Efficient-Tuning/stargazers">
      <img src="https://img.shields.io/github/stars/hiyouga/LLaMA-Efficient-Tuning" alt="GitHub stars">
    </a></td>
    <td>4</sup></td>
    <td>5</td>
    <td>~20</td>
    <td>1<sup>(a)</sup></td>
    <td>âœ”ï¸</td>
    <td>âŒ</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/hiyouga/LLaMA-Efficient-Tuning?label=last%20update">
    </a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/AberHu/Knowledge-Distillation-Zoo">Knowledge-Distillation-Zoo</a></td>
    <td><a href="https://github.com/AberHu/Knowledge-Distillation-Zoo/stargazers">
      <img src="https://img.shields.io/github/stars/AberHu/Knowledge-Distillation-Zoo" alt="GitHub stars">
    </a></td>
    <td>20</td>
    <td>2</td>
    <td>2</td>
    <td>1<sup>(b)</sup></td>
    <td>âŒ</td>
    <td>âŒ</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/AberHu/Knowledge-Distillation-Zoo?label=last%20update">
    </a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/sicara/easy-few-shot-learning">Easy Few-Shot Learning</a></td>
    <td><a href="https://github.com/sicara/easy-few-shot-learning/stargazers">
      <img src="https://img.shields.io/github/stars/sicara/easy-few-shot-learning" alt="GitHub stars">
    </a></td>
    <td>10</td>
    <td>3</td>
    <td>2</td>
    <td>1<sup>(b)</sup></td>
    <td>âŒ</td>
    <td>âŒ</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/sicara/easy-few-shot-learning?label=last%20update">
    </a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/mlfoundations/model-soups">Model soups</a></td>
    <td><a href="https://github.com/mlfoundations/model-soups/stargazers">
      <img src="https://img.shields.io/github/stars/mlfoundations/model-soups" alt="GitHub stars">
    </a></td>
    <td>3</sup></td>
    <td>3</td>
    <td>5</td>
    <td>1<sup>(c)</sup></td>
    <td>âŒ</td>
    <td>âŒ</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/mlfoundations/model-soups?label=last%20update">
    </a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/samuela/git-re-basin">Git Re-Basin</a></td>
    <td><a href="https://github.com/samuela/git-re-basin/stargazers">
      <img src="https://img.shields.io/github/stars/samuela/git-re-basin" alt="GitHub stars">
    </a></td>
    <td>3</sup></td>
    <td>5</td>
    <td>4</td>
    <td>1<sup>(c)</sup></td>
    <td>âŒ</td>
    <td>âŒ</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/samuela/git-re-basin?label=last%20update">
    </a></td>
  </tr>
  <tr>
    <td colspan="9" style="border-bottom: 2px solid grey;"></td>
  </tr>
  </tr>
    <tr>
    <td><b>ZhiJian</b></td>
    <!-- <td><a href="https://github.com/adapter-hub/adapter-transformers/stargazers">
      <img src="https://img.shields.io/github/stars/zhangyikaii/LAMDA-ZhiJian" alt="GitHub stars">
    </a></td> -->
    <td>ğŸ™Œ</td>
    <td>30+</td>
    <td>~50</td>
    <td>19</td>
    <td>3<sup>(a,b,c)</sup></td>
    <td>âœ”ï¸</td>
    <td>âœ”ï¸</td>
    <td>
    <a>
      <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/zhangyikaii/LAMDA-ZhiJian?label=last%20update">
    </a></td>
  </tr>

</table>


<sup><b>(1)</b>: æ›´æ–°æ—¥æœŸ: 2023-08-05</sup>
<sup><b>(2)</b>: æ¶‰åŠé¢†åŸŸï¼š(a) æ„å»ºè€…æ¨¡å—ï¼›(b) å¾®è°ƒè€…æ¨¡å—ï¼›(c) èåˆè€…æ¨¡å—ï¼›</sup>

### ğŸ“¦ å¤ç° SoTA ç»“æœ

**ZhiJian** å›ºå®šäº†éšæœºç§å­ï¼Œä»¥ç¡®ä¿å¤ç°ç»“æœï¼Œä»…åœ¨ä¸åŒè®¾å¤‡é—´å­˜åœ¨å¾®å°ä¸åŒ

&nbsp;

## å¦‚ä½•è´¡çŒ®

ZhiJian ç›®å‰æ­£åœ¨ç§¯æåœ°å¼€å‘ä¸­ï¼Œæ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ã€‚æ— è®ºæ‚¨æ˜¯å¦å¯¹é¢„è®­ç»ƒæ¨¡å‹ã€ç›®æ ‡æ•°æ®æˆ–åˆ›æ–°çš„é‡ç”¨æ–¹æ³•æœ‰å“ªäº›è§è§£ï¼Œæˆ‘ä»¬éƒ½çƒ­åˆ‡åœ°é‚€è¯·æ‚¨åŠ å…¥æˆ‘ä»¬ï¼Œå…±åŒä½¿ ZhiJian å˜å¾—æ›´åŠ ä¼˜ç§€ã€‚å¦‚æœæ‚¨å¸Œæœ›æäº¤å®è´µçš„è´¡çŒ®ï¼Œè¯·ç‚¹å‡» [è¿™é‡Œ](https://zhijian.readthedocs.io/en/latest/contributing.html)ã€‚


&nbsp;

## å¼•ç”¨ ZhiJian

```latex
@misc{zhang2023zhijian,
  title={ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse}, 
  author={Yi-Kai Zhang and Lu Ren and Chao Yi and Qi-Wei Wang and De-Chuan Zhan and Han-Jia Ye},
  year={2023},
  eprint={2308.09158},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{zhijian2023,
  author = {ZhiJian Contributors},
  title = {LAMDA-ZhiJian},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/zhangyikaii/LAMDA-ZhiJian}}
}
```
